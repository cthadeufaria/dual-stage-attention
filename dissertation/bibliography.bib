% bibliograhy entries 

@misc{sandvine_global_2023,
    author = {{Sandvine}},
    title = {Sandvine's 2023 Global Internet Phenomena Report shows 24\% jump in video traffic with Netflix volume overtaking YouTube},
    url = {https://www.sandvine.com/press-releases/sandvines-2023-global-internet-phenomena-report-shows-24-jump-in-video-traffic-with-netflix-volume-overtaking-youtube},
    urldate = {2025-01-10},
    year = {2023},
    note = {Press Release},
}

@article{mittal2012completely,
  title={Making a "completely blind" image quality analyzer},
  author={Mittal, Anish and Soundararajan, Rajiv and Bovik, Alan C},
  journal={IEEE Signal Processing Letters},
  volume={20},
  number={3},
  pages={209--212},
  year={2012},
  publisher={IEEE}
}

@article{zhang2015feature,
  title={A feature-enriched completely blind image quality evaluator},
  author={Zhang, Lin and Zhang, Lei and Bovik, Alan C},
  journal={IEEE Transactions on Image Processing},
  volume={24},
  number={8},
  pages={2579--2591},
  year={2015},
  publisher={IEEE}
}

@article{mittal2012no,
  title={No-reference image quality assessment in the spatial domain},
  author={Mittal, Anish and Moorthy, Anush K and Bovik, Alan C},
  journal={IEEE Transactions on Image Processing},
  volume={21},
  number={12},
  pages={4695--4708},
  year={2012},
  publisher={IEEE}
}

@article{min2024perceptual,
  title={Perceptual video quality assessment: a survey},
  author={Min, Xiongkuo and Duan, Huiyu and Sun, Wei and Zhu, Yucheng and Zhai, Guangtao},
  journal={SCIENCE CHINA Information Sciences},
  volume={67},
  number={11},
  pages={211301:1--211301:57},
  year={2024},
  publisher={Springer},
  doi={10.1007/s11432-024-4133-3},
  note={Published online 17 October 2024}
}

@article{li2023unified,
  title={Unified Quality Assessment of In-the-Wild Videos with Mixed Datasets Training},
  author={Li, Dingquan and Jiang, Tingting and Jiang, Ming},
  journal={arXiv preprint arXiv:2301.01234},
  year={2023}
}

@misc{itu2012recommendation,
  title={Methodology for the subjective assessment of the quality of television pictures},
  author={{ITU-R Recommendation BT.500-13}},
  year={2012},
  institution={International Telecommunication Union},
  note={Series B},
  howpublished={\url{https://www.itu.int}},
}

@inproceedings{wu2022fastvqa,
  author = {Wu, H. and Chen, C. and Hou, J. and others},
  title = {Fast-VQA: Efficient End-to-End Video Quality Assessment with Fragment Sampling},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  year = {2022},
  pages = {538--554},
}

@article{wang2004ssim,
  author    = {Zhou Wang and Alan C. Bovik and Hamid R. Sheikh and Eero P. Simoncelli},
  title     = {Image quality assessment: from error visibility to structural similarity},
  journal   = {IEEE Transactions on Image Processing},
  volume    = {13},
  number    = {4},
  pages     = {600--612},
  year      = {2004},
  publisher = {IEEE},
  doi       = {10.1109/TIP.2003.819861}
}

@inproceedings{zeng2012_3dssim,
  author    = {Kede Zeng and Zhou Wang},
  title     = {3D-{SSIM} for Video Quality Assessment},
  booktitle = {Proceedings of the {IEEE} International Conference on Image Processing},
  year      = {2012},
  pages     = {621--624}
}

@inproceedings{sun2022deep,
  author    = {W. Sun and X. Min and W. Lu and others},
  title     = {A deep learning based no-reference quality assessment model for UGC videos},
  booktitle = {Proceedings of the ACM International Conference on Multimedia},
  year      = {2022},
  pages     = {856--865},
}

% Brunnström, K. et al. (2013)  
@article{brunnstrom2013qualinet,  
  title={Qualinet white paper on definitions of quality of experience},  
  author={Brunnström, Kjell and Beker, Sylvia and De Moor, Katrien and Dooms, Ann and Egger, Sebastian and Garcia, Maria-Nefeli and Hossfeld, Tobias and Jumisko-Pyykkö, Satu and Keimel, Christian and Larabi, Mohamed-Chaker and others},  
  journal={European Network on Quality of Experience in Multimedia Systems and Services (COST Action IC 1003)},  
  volume={3},  
  year={2013}  
}  

% Wang, Z. et al. (2003) - MS-SSIM  
@article{wang2003multiscale,  
  title={Multiscale structural similarity for image quality assessment},  
  author={Wang, Zhou and Simoncelli, Eero P and Bovik, Alan C},  
  journal={IEEE Asilomar Conference on Signals, Systems \& Computers},  
  volume={2},  
  pages={1398--1402},  
  year={2003},  
  publisher={IEEE}  
}  

% He, K. et al. (2016) - ResNet  
@inproceedings{he2016deep,  
  title={Deep residual learning for image recognition},  
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},  
  booktitle={IEEE CVPR},  
  pages={770--778},  
  year={2016}  
}  

% Dosovitskiy, A. et al. (2020) - ViT  
@article{dosovitskiy2020image,  
  title={An image is worth 16x16 words: Transformers for image recognition at scale},  
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},  
  journal={arXiv preprint arXiv:2010.11929},  
  year={2020}  
} 

@article{huynh2012scope,
  author    = {Q. Huynh-Thu and M. Ghanbari},
  title     = {Scope of validity of {PSNR} in image/video quality assessment},
  journal   = {Electronics Letters},
  volume    = {44},
  number    = {13},
  pages     = {800--801},
  year      = {2008},
  doi       = {10.1049/el:20080522},
}

@inproceedings{lee2021video,  
  title={Video quality assessment with serial dependence modeling},  
  author={Lee, Jongyoo and Kim, Jincheol and Ahn, Sanghoon and Lee, Sangyoun},  
  booktitle={IEEE ICIP},  
  pages={3118--3122},  
  year={2021}  
}  

@article{zhang2017mixup,  
  title={mixup: Beyond empirical risk minimization},  
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},  
  journal={arXiv preprint arXiv:1710.09412},  
  year={2017}  
}  

@article{liu2021swin,  
  title={Swin transformer: Hierarchical vision transformer using shifted windows},  
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},  
  journal={arXiv preprint arXiv:2103.14030},  
  year={2021}  
}  

@inproceedings{selvaraju2017grad,  
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},  
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},  
  booktitle={IEEE ICCV},  
  pages={618–626},  
  year={2017}  
} 

@inproceedings{singh2012qoe,  
  title={Quality of experience estimation for adaptive http/tcp video streaming using H.264/AVC},  
  author={Singh, Kamal Deep and Hadjadj-Aoul, Yassine and Rubino, Gerardo},  
  booktitle={IEEE Consumer Communications and Networking Conference},  
  pages={127--131},  
  year={2012}  
}  

@article{li2022weakly,  
  title={From whole video to frames: Weakly-supervised domain adaptive continuous-time QoE evaluation},  
  author={Li, Lin and Chen, Peng and Lin, Weisi and et al.},  
  journal={IEEE Transactions on Image Processing},  
  volume={31},  
  pages={4937--4951},  
  year={2022}  
}  

@article{jia2024continuous,  
  title={Continuous and overall quality of experience evaluation for streaming video based on rich features exploration and dual-stage attention},  
  author={Jia, Ziyi and Min, Xiongkuo and Sun, Wei and et al.},  
  journal={IEEE Transactions on Circuits and Systems for Video Technology},  
  year={2024}  
}  

@article{itu2017p800,
  title={Recommendation ITU-T P.800: Methods for subjective determination of transmission quality},
  author={International Telecommunication Union},
  journal={ITU-T Recommendation P.800},
  year={2017},
  publisher={International Telecommunication Union},
  url={https://www.itu.int/rec/T-REC-P.800}
}

@inproceedings{hosu2017konvid,
title = {The Konstanz natural video database 
(KoNViD-1k)},
author = {Hosu, Vlad and Hahn, Franz and Jenadeleh, 
Mohsen and Lin, Hanhe and Men, Hui and Szir{\'a}nyi,
Tam{\'a}s and Li, Shujun and Saupe, Dietmar},
booktitle = {2017 Ninth International Conference on 
Quality of Multimedia Experience (QoMEX)},
pages = {1--6},
year = {2017},
organization = {IEEE}}

@article{sinno2018large,
  author    = {Zhou Wang and Alan Conrad Bovik},
  title     = {Large-Scale Study of Perceptual Video Quality},
  journal   = {IEEE Transactions on Image Processing},
  volume    = {28},
  number    = {2},
  pages     = {612--627},
  year      = {2018},
  doi       = {10.1109/TIP.2018.2872062}
}

@inproceedings{wang2019youtube,
  author    = {Yu Wang and Sriram Inguva and Behtash Adsumilli},
  title     = {YouTube UGC Dataset for Video Compression Research},
  booktitle = {Proc. IEEE Int. Workshop on Multimedia Signal Processing (MMSP)},
  year      = {2019},
  pages     = {1--5},
  doi       = {10.1109/MMSP.2019.8901748}
}

@article{itti1998model,
author = {Itti, Laurent and Koch, Christof and Niebur, Ernst},
year = {1998},
month = {12},
pages = {1254 - 1259},
title = {A Model of Saliency-based Visual Attention for Rapid Scene Analysis},
volume = {20},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
doi = {10.1109/34.730558}
}

@article{BAMPIS2018218,
title = {Feature-based prediction of streaming video QoE: Distortions, stalling and memory},
journal = {Signal Processing: Image Communication},
volume = {68},
pages = {218-228},
year = {2018},
issn = {0923-5965},
doi = {https://doi.org/10.1016/j.image.2018.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S0923596518303679},
author = {Christos G. Bampis and Alan C. Bovik},
keywords = {QoE prediction, Adaptive video streaming, Perceptual video quality assessment}
}

@inproceedings{paszke2019pytorch,
  title={PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle={Advances in Neural Information Processing Systems 32},
  editor={H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alché-Buc and E. Fox and R. Garnett},
  pages={8024--8035},
  year={2019},
  publisher={Curran Associates, Inc.},
  url={http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{hosu2017konstanz,
  title={The {K}on{V}i{D}-1k dataset for video quality assessment},
  author={Hosu, Vlad and Hahn, Franz and Jenadeleh, Mohsen and Lin, Hanhe and Men, Hui and Szirányi, Tamás and Li, Shujun and Saupe, Dietmar},
  booktitle={2017 Ninth International Conference on Quality of Multimedia Experience (QoMEX)},
  pages={1--3},
  year={2017},
  organization={IEEE},
  doi={10.1109/QoMEX.2017.7965673}
}

@inproceedings{live_nflx_conf,
  author    = {Deepti Ghadiyaram and Alan C. Bovik},
  title     = {LIVE-NFLX-II: A Netflix Video Quality Assessment Database},
  booktitle = {IEEE International Conference on Image Processing (ICIP)},
  year      = {2020},
  pages     = {3094--3098},
  doi       = {10.1109/ICIP40778.2020.9190972}
}

@inproceedings {fulton2022benefits,
author = {Kelsey R. Fulton and Anna Chan and Daniel Votipka and Michael Hicks and Michelle L. Mazurek},
title = {Benefits and Drawbacks of Adopting a Secure Programming Language: Rust as a Case Study},
booktitle = {Seventeenth Symposium on Usable Privacy and Security (SOUPS 2021)},
year = {2021},
isbn = {978-1-939133-25-0},
pages = {597--616},
url = {https://www.usenix.org/conference/soups2021/presentation/fulton},
publisher = {USENIX Association},
month = aug
}

@techreport{johansson2023transitioning,
  author       = {Johansson, Samuel and Rappe, Ludvig},
  title        = {Transitioning from C to Rust in Media Streaming Development: An Industrial Case Study},
  institution  = {Department of Computer Science, Lund University (LTH)},
  year         = {2023},
  number       = {LU-CS-EX: 2020-06},
  issn         = {1650-2884},
  type         = {Master's Thesis},
  url          = {https://www.diva-portal.org/smash/get/diva2:1771846/FULLTEXT01.pdf},
  note         = {Available via DiVA portal}
}

@article{carnelos2025microflow,
  title = {MicroFlow: An Efficient Rust-Based Inference Engine for TinyML},
  journal = {Internet of Things},
  volume = {30},
  pages = {101498},
  year = {2025},
  issn = {2542-6605},
  doi = {https://doi.org/10.1016/j.iot.2025.101498},
  url = {https://www.sciencedirect.com/science/article/pii/S2542660525000113},
  author = {Matteo Carnelos and Francesco Pasti and Nicola Bellotto},
  keywords = {TinyML, Rust, Neural networks, Embedded systems, IoT}
}

@article{ham2019nnstreamer,
  title={NNStreamer: Stream Processing Paradigm for Neural Networks, Toward Efficient Development and Execution of On-Device AI Applications},
  author={Ham, MyungJoo and Moon, Ji Joong and Lim, Geunsik and Song, Wook and Jung, Jaeyun and Ahn, Hyoungjoo and Woo, Sangjung and Cho, Youngchul and Park, Jinhyuck and Oh, Sewon and Kim, Hong-Seok},
  journal={Samsung Research White Paper},
  year={2019},
  institution={Samsung Electronics}
}

@misc{gstreamer1999,
  title = {GStreamer: Open Source Multimedia Framework},
  howpublished = {\url{https://gstreamer.freedesktop.org/}},
  year = {1999},
  note = {(Accessed Jan 3, 2019)}
}

@article{beltran2024review,
  title = {A Review on Resource-Constrained Embedded Vision Systems-Based Tiny Machine Learning for Robotic Applications},
  author = {Beltrán-Escobar, Miguel and Alarcón, Teresa E. and Rumbo-Morales, Jesse Y. and López, Sonia and Ortiz-Torres, Gerardo and Sorcia-Vázquez, Felipe D. J.},
  journal = {Sensors},
  year = {2024},
  volume = {24},
  number = {1},
  pages = {234},
  doi = {10.3390/s24010234}
}

@article{sharma2023rust,
  title = {Rust for Embedded Systems: Current State, Challenges and Open Problems},
  author = {Sharma, Abhishek and Sharma, Shubham and Torres-Arias, Santiago and Machiry, Aravind},
  journal = {arXiv preprint arXiv:2311.05063},
  year = {2023},
  url = {https://arxiv.org/abs/2311.05063}
}

@misc{fan2021pytorchvideodeeplearninglibrary,
  title={PyTorchVideo: A Deep Learning Library for Video Understanding}, 
  author={Haoqi Fan and Tullie Murrell and Heng Wang and Kalyan Vasudev Alwala and Yanghao Li and Yilei Li and Bo Xiong and Nikhila Ravi and Meng Li and Haichuan Yang and Jitendra Malik and Ross Girshick and Matt Feiszli and Aaron Adcock and Wan-Yen Lo and Christoph Feichtenhofer},
  year={2021},
  eprint={2111.09887},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2111.09887}
}

@INPROCEEDINGS{5206848,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}
}

@misc{kay2017kineticshumanactionvideo,
  title={The Kinetics Human Action Video Dataset}, 
  author={Will Kay and Joao Carreira and Karen Simonyan and Brian Zhang and Chloe Hillier and Sudheendra Vijayanarasimhan and Fabio Viola and Tim Green and Trevor Back and Paul Natsev and Mustafa Suleyman and Andrew Zisserman},
  year={2017},
  eprint={1705.06950},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1705.06950}
}

@misc{nanbhasblog,
  author = {Bhaswar, Nan},
  title = {Accessing a particular layer from the model using PyTorch forward hooks},
  url = {https://web.stanford.edu/~nanbhas/blog/forward-hooks-pytorch/#accessing-a-particular-layer-from-the-model},
  year = {2022},
  note = {Accessed: 2025-06-11}
}

@misc{torchhooksdoc,
  title = {torch.nn.modules.module.register\_module\_forward\_hook},
  howpublished = {\url{https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_hook.html}},
  note = {Accessed: 2025-06-11}
}

@article{feichtenhofer2019slowfast,
  author       = {Christoph Feichtenhofer and
                  Haoqi Fan and
                  Jitendra Malik and
                  Kaiming He},
  title        = {SlowFast Networks for Video Recognition},
  journal      = {CoRR},
  volume       = {abs/1812.03982},
  year         = {2018},
  url          = {http://arxiv.org/abs/1812.03982},
  eprinttype    = {arXiv},
  eprint       = {1812.03982},
  timestamp    = {Mon, 29 Apr 2019 07:40:56 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1812-03982.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{goodfellow2016deep,
  title={Deep Learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT Press},
  url={https://www.deeplearningbook.org/}
}

@inproceedings{vaswani2017attention,
  title={Attention Is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5998--6008},
  year={2017},
  volume={30},
  organization={Curran Associates, Inc.},
  url={https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html}
}

@article{bai2018empirical,
  title={An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling},
  author={Bai, Shaojie and Kolter, J Zico and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1803.01271},
  year={2018}
}

@misc{pytorch_tutorials,
  key          = {PyTorch},
  title        = {Defining a Neural Network (PyTorch Official Recipe)},
  year         = {2023},
  howpublished = {\url{https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html}},
  note         = {Accessed: 2025-03-16}
}

@article{hendrycks2016gaussian,
  title={Gaussian Error Linear Units (GELUs)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{alpert1991sscqe,
  title={SSCQE (single stimulus continuous quality evaluation): A new subjective assessment method introduced in ITU-R recommendation 500–7: Presentation and results},
  author={Alpert, Tom and Evain, Jean-Pierre},
  journal={Proc. Int. Workshop on HDTV},
  year={1991}
}

@article{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}

@inproceedings{deng2009imagenet,
  title={ImageNet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={248--255},
  year={2009},
  organization={IEEE}
}

@article{kay2017kinetics,
  title={The Kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}

@article{loshchilov2018decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2018}
}

@inproceedings{liu2019variance,
  title={On the variance of the adaptive learning rate and beyond},
  author={Liu, Shuo and Wang, Tianyi and Liu, Yuzhe and Chen, Jian and Yu, Philip S and Wang, Lu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={4606--4613},
  year={2019}
}

@article{micikevicius2018mixed,
  title={Mixed precision training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Greg and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and others},
  journal={arXiv preprint arXiv:1710.03740},
  year={2018}
}

@article{prechelt1998early,
  title     = {Early Stopping — But When?},
  author    = {Prechelt, Lutz},
  booktitle = {Neural Networks: Tricks of the Trade},
  pages     = {55--69},
  year      = {1998},
  publisher = {Springer},
  doi       = {10.1007/3-540-49430-8_3}
}

@misc{li2019qoe,
      title={DeepQoE: A unified Framework for Learning to Predict Video QoE}, 
      author={Huaizheng Zhang and Han Hu and Guanyu Gao and Yonggang Wen and Kyle Guan},
      year={2018},
      eprint={1804.03481},
      archivePrefix={arXiv},
      primaryClass={cs.MM},
      url={https://arxiv.org/abs/1804.03481}, 
}

@book{bishop2006pattern,
  title={Pattern Recognition and Machine Learning},
  author={Bishop, Christopher M.},
  year={2006},
  publisher={Springer},
  isbn={9780387310732}
}

@article{sheikh2006statistical,
  author    = {Hamid R. Sheikh and Alan C. Bovik},
  title     = {Image Information and Visual Quality},
  journal   = {IEEE Transactions on Image Processing},
  volume    = {15},
  number    = {2},
  pages     = {430--444},
  year      = {2006},
  doi       = {10.1109/TIP.2005.859378}
}

@article{mittal2012vbed,
  author    = {Anish Mittal and Rajiv Soundararajan and Alan C. Bovik},
  title     = {Making a "Completely Blind" Image Quality Analyzer},
  journal   = {IEEE Signal Processing Letters},
  volume    = {20},
  number    = {3},
  pages     = {209--212},
  year      = {2013},
  doi       = {10.1109/LSP.2012.2227726}
}

@techreport{dash-if2022,
  title        = {{DASH-IF Interoperability Guidelines: IOP Version 5.0 - Part 1: Overview, Architecture and Interfaces}},
  author       = {{DASH Industry Forum}},
  institution  = {DASH Industry Forum},
  type         = {Technical Report},
  number       = {IOP v5.0.0 Part 1},
  year         = {2022},
  month        = jun,
  note         = {Based on ISO/IEC 23009-1:2022; available at \url{https://dashif.org/guidelines/}},
}